{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Get OPENAI_API_KEY from .env file\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY')\n",
    "os.environ[\"OPENAI_ORGANIZATION\"] = os.getenv('OPENAI_ORGANIZATION')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up the vector database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from weaviate import Client\n",
    "\n",
    "# Initialize Weaviate client\n",
    "client = Client(\"http://localhost:8080\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_schema():\n",
    "    \"\"\"\n",
    "    Creates the schema for the 'code_example' class in Weaviate.\n",
    "    \"\"\"\n",
    "    class_obj = {\n",
    "        \"class\": \"code_example\",\n",
    "        \"vectorizer\": \"text2vec-openai\",\n",
    "        \"moduleConfig\": {\n",
    "            \"text2vec-openai\": {}\n",
    "        },\n",
    "        \"properties\": [\n",
    "            {\n",
    "                \"name\": \"file_name\",\n",
    "                \"dataType\": [\"string\"],\n",
    "                \"description\": \"File name associated with the code\"\n",
    "            },\n",
    "            {\n",
    "                \"name\": \"tags\",\n",
    "                \"dataType\": [\"string[]\"],\n",
    "                \"description\": \"Tags associated with the code\"\n",
    "            },\n",
    "            {\n",
    "                \"name\": \"description\",\n",
    "                \"dataType\": [\"text\"],\n",
    "                \"description\": \"Description of the code\",\n",
    "                \"moduleConfig\": {\n",
    "                    \"text2vec-openai\": {\n",
    "                        \"vectorizePropertyName\": 'true'\n",
    "                    }\n",
    "                },\n",
    "            },\n",
    "            {\n",
    "                \"name\": \"code\",\n",
    "                \"dataType\": [\"text\"],\n",
    "                \"description\": \"The actual code\"\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    client.schema.delete_all()  # Clear existing schema\n",
    "    client.schema.create_class(class_obj)  # Create the new class\n",
    "\n",
    "# Create the schema\n",
    "create_schema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Populate the database with code examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from weaviate.util import generate_uuid5 \n",
    "\n",
    "def populate_weaviate(documents):\n",
    "    \"\"\"\n",
    "    Populates the Weaviate database with the provided documents.\n",
    "    Clears the database if it is already populated.\n",
    "    \"\"\"\n",
    "\n",
    "    # Configure batch\n",
    "    client.batch.configure(batch_size=len(documents))\n",
    "\n",
    "    # Initialize a batch process\n",
    "    with client.batch as batch:\n",
    "        # Batch import data\n",
    "        for i, doc in enumerate(documents):\n",
    "            print(f\"Importing document: {i+1}\")\n",
    "            try:\n",
    "                properties = {\n",
    "                    \"file_name\": doc[\"file_name\"],\n",
    "                    \"tags\": doc[\"tags\"],\n",
    "                    \"description\": doc[\"description\"],\n",
    "                    \"code\": doc[\"code\"]\n",
    "                }\n",
    "                batch.add_data_object(\n",
    "                    data_object=properties,\n",
    "                    class_name=\"code_example\",\n",
    "                    uuid=generate_uuid5(properties[\"file_name\"])\n",
    "                )\n",
    "            except Exception as e:\n",
    "                print(f\"Error adding document to Weaviate: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import yaml\n",
    "\n",
    "# Define the path to the data directory\n",
    "DATA_DIR = \"../data\"\n",
    "\n",
    "# Define a function to extract tags, description, and code from a file\n",
    "def extract_information(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        content = file.read()\n",
    "\n",
    "    # Extract the docstring\n",
    "    docstring_start = content.find('\"\"\"') + 3\n",
    "    docstring_end = content.find('\"\"\"', docstring_start)\n",
    "    docstring = content[docstring_start:docstring_end]\n",
    "\n",
    "    # Parse the docstring as YAML\n",
    "    metadata = yaml.safe_load(docstring)\n",
    "\n",
    "    # Extract tags and description\n",
    "    tags = metadata['tags']\n",
    "    description = metadata['description']\n",
    "\n",
    "    # Extract code\n",
    "    code_start = content.find('\"\"\"', docstring_end) + len('\"\"\"')\n",
    "    if code_start != -1:\n",
    "        code = content[code_start:].strip()\n",
    "    else:\n",
    "        print(f\"Error in file {file_path}: No code found after docstring.\")\n",
    "        return\n",
    "\n",
    "    return {\n",
    "        'file_name': os.path.basename(file_path),\n",
    "        'tags': tags,\n",
    "        'description': description,\n",
    "        'code': code\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_files():\n",
    "    \"\"\"\n",
    "    Modified function to process files and populate Weaviate database.\n",
    "    \"\"\"\n",
    "    documents = []\n",
    "    for file_name in os.listdir(DATA_DIR):\n",
    "        if file_name.endswith('.py'):\n",
    "            file_path = os.path.join(DATA_DIR, file_name)\n",
    "            data = extract_information(file_path)\n",
    "            \n",
    "            if data:\n",
    "                documents.append({\"file_name\": file_name, **data})\n",
    "            else:\n",
    "                log_error(file_name, \"tags, description, or code\")\n",
    "\n",
    "    # Populate Weaviate with extracted documents\n",
    "    populate_weaviate(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing document: 1\n",
      "Importing document: 2\n",
      "Importing document: 3\n",
      "Importing document: 4\n",
      "Importing document: 5\n",
      "Importing document: 6\n",
      "Importing document: 7\n",
      "Importing document: 8\n",
      "Importing document: 9\n"
     ]
    }
   ],
   "source": [
    "# Run the main function\n",
    "process_files()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_collection(query):\n",
    "    response = (\n",
    "        client.query\n",
    "        .get(\"code_example\", [\"description\", \"code\", \"file_name\", \"tags\"])\n",
    "        .with_near_text({\n",
    "            \"concepts\": [query]\n",
    "        })\n",
    "        .with_limit(10)\n",
    "        .with_additional([\"distance\"])\n",
    "        .do()\n",
    "    )\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_query_results(query_result):\n",
    "    result_string = \"\"\n",
    "    for result in query_result['data']['Get']['Code_example']:\n",
    "        result_string += \"# Example:\\n\"\n",
    "        result_string += f\"{result['code']}\\n\"\n",
    "    return result_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# Example:\\n# Create a chain that does the following and streams the response:\\n# - Accept nothing as input\\n# - Format messages from System and Human as a prompt\\n# - Pass messages to OpenAI\\n# - Parse the OpenAI response as a string\\n# - Stream the response\\n\\nfrom langchain.chat_models import ChatOpenAI\\nfrom langchain.prompts import ChatPromptTemplate\\nfrom langchain.schema.messages import HumanMessage, SystemMessage\\nfrom langchain.schema.output_parser import StrOutputParser\\n\\n# Generate system and human messages\\nmessages = [\\n    SystemMessage(content=\"You\\'re a helpful assistant\"),\\n    HumanMessage(content=\"What is the purpose of model regularization?\"),\\n]\\n\\nprompt = ChatPromptTemplate.from_messages(messages)\\nmodel = ChatOpenAI()\\noutput_parser = StrOutputParser()\\n\\nchain = prompt | model | output_parser\\n\\n# Stream the chain\\nfor chunk in chain.stream({}):\\n    print(chunk, end=\"\", flush=True)\\n# Example:\\n# Create a chain that does the following:\\n# - Accept a string as input\\n# - Retrieve matching documents from a DocArrayInMemorySearch vectorstore, and pass through the results and the original question to a prompt\\n# - Format the prompt using variables from the object\\n# - Pass the prompt to OpenAI\\n# - Parse the OpenAI response as a string\\n\\nfrom langchain.chat_models import ChatOpenAI\\nfrom langchain.embeddings import OpenAIEmbeddings\\nfrom langchain.prompts import ChatPromptTemplate\\nfrom langchain.schema.output_parser import StrOutputParser\\nfrom langchain.schema.runnable import RunnableParallel, RunnablePassthrough\\nfrom langchain.vectorstores import DocArrayInMemorySearch\\n\\nvectorstore = DocArrayInMemorySearch.from_texts(\\n    [\"Tom likes clouds\", \"bears like honey\"],\\n    embedding=OpenAIEmbeddings(),\\n)\\nretriever = vectorstore.as_retriever()\\n\\ntemplate = \"\"\"Answer the question:\\n{context}\\n\\nQuestion: {question}\\n\"\"\"\\nprompt = ChatPromptTemplate.from_template(template)\\nmodel = ChatOpenAI()\\noutput_parser = StrOutputParser()\\n\\nsetup_and_retrieval = RunnableParallel(\\n    {\"context\": retriever, \"question\": RunnablePassthrough()}\\n)\\n\\nchain = setup_and_retrieval | prompt | model | output_parser\\n\\nchain.invoke(\"what does Tom like?\")\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_request = \"\"\"\n",
    "- Accept a string named answer\n",
    "- Format string as an object to pass to the prompt\n",
    "- Create System and Human messages templates. The System message has formatted output instructions via Pydantic. The Human message uses answer as context. Output instructions format to a Pydantic schema for hmw_question with a question (description: up to 10 word \"how might we\" question) and a role (description: either marketing, technology, or design) \n",
    "- Pass messages to OpenAI\n",
    "- Parse response using Pydantic\n",
    "\"\"\"\n",
    "\n",
    "# Query the collection\n",
    "query_result = query_collection(new_request)\n",
    "\n",
    "# Format and print the results\n",
    "format_query_results(query_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
