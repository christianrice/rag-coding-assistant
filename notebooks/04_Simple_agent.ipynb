{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install --upgrade langchain langsmith langgraph langchain_openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Get OPENAI_API_KEY from .env file\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "os.environ[\"OPENAI_ORGANIZATION\"] = os.getenv(\"OPENAI_ORGANIZATION\")\n",
    "\n",
    "# Initialize LangSmith\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"Multi Agent Collaboration\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up the Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.prompts.chat import SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain.schema.runnable import RunnableParallel, RunnablePassthrough, RunnableLambda\n",
    "\n",
    "# Set up the system template with a variable for context\n",
    "system_template = \"\"\"\n",
    "Generate working code for a Jupyter Notebook based on the user's request. Your code should use LangChain, and specifically use LangChain's Expression Language in structuring your code.\n",
    "\n",
    "Strictly adhere to the code examples delimited by triple backticks below as context for how LangChain's API works. DO NOT use any patterns that you do not find in the example below, unless you are 100% certain they work in LangChain:\n",
    "\n",
    "```\n",
    "{context}\n",
    "```\n",
    "\n",
    "Before sharing, double check your work. I will tip you $100 if your code is perfect.\n",
    "\n",
    "Do not explain your work, just share working code.\n",
    "\"\"\"\n",
    "system_message_prompt = SystemMessagePromptTemplate.from_template(system_template)\n",
    "\n",
    "# Set up the human template with a variable for the request\n",
    "human_template = \"\"\"\n",
    "{request}\n",
    "\"\"\"\n",
    "human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([system_message_prompt, human_message_prompt])\n",
    "model = ChatOpenAI(model=\"gpt-3.5-turbo-1106\", temperature=0)\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "code_writing_runnable = prompt | model | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import ToolExecutor\n",
    "\n",
    "tool_executor = ToolExecutor(tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define the response schema for our agent\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "\n",
    "class Response(BaseModel):\n",
    "    \"\"\"final answer to the user\"\"\"\n",
    "\n",
    "    result: int = Field(description=\"the result of the computation\")\n",
    "    explanation: str = Field(\n",
    "        description=\"explanation of the steps taken to get the result\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Set up the agent's tools\n",
    "\n",
    "tools = []\n",
    "pseudo_tools_visible = [\n",
    "    \"Retrieve Context\",\n",
    "    \"Write Code\",\n",
    "    \"Review Code\",\n",
    "    # \"Save Code\",\n",
    "]\n",
    "pseudo_tools_hidden = [\n",
    "    \"Store Request\",\n",
    "]\n",
    "\n",
    "agent_tools = tools + pseudo_tools_visible + pseudo_tools_hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Retrieve Context', 'Write Code', 'Review Code', 'Store Request']\n"
     ]
    }
   ],
   "source": [
    "print(agent_tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.pydantic_v1 import BaseModel\n",
    "from enum import Enum\n",
    "from langchain.tools import StructuredTool\n",
    "\n",
    "\n",
    "# Set the agent options, which is FINISH plus all tools, with the exception of the hidden tools\n",
    "agent_options = [\"FINISH\"] + agent_tools\n",
    "agent_options = [item for item in agent_options if item not in pseudo_tools_hidden]\n",
    "\n",
    "RouteOptions = Enum(\"RouteOptions\", {option: option for option in agent_options})\n",
    "\n",
    "\n",
    "class RouteInput(BaseModel):\n",
    "    next: RouteOptions\n",
    "\n",
    "\n",
    "def route(route: str) -> str:\n",
    "    return route\n",
    "\n",
    "\n",
    "router = StructuredTool.from_function(\n",
    "    func=route,\n",
    "    name=\"route\",\n",
    "    description=\"Select the next team member to use\",\n",
    "    args_schema=RouteInput,\n",
    "    return_direct=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_openai_functions_agent\n",
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "from langchain.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    MessagesPlaceholder,\n",
    ")\n",
    "\n",
    "system_prompt_initial = \"\"\"\n",
    "You are a supervisor tasked with managing a development team consisting of the following members: {members}.\n",
    "\n",
    "Given the following feature request from a user, respond with the worker to act next.\n",
    "\n",
    "Each worker will perform a task and respond with their results and status. This task is complete as soon as you know a worker has retrieved context related to the user's feature request. When the task is complete, respond with FINISH.\n",
    "\n",
    "You typically follow this pattern:\n",
    "\n",
    "1) Retrieve context related to the user's query. This is a REQUIRED step before writing code\n",
    "2) Write code to solve the problem\n",
    "3) Save the code you have written once the reviewer has approved the code\n",
    "\"\"\"\n",
    "\n",
    "# Get the prompt to use - you can modify this!\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        SystemMessagePromptTemplate.from_template(system_prompt_initial),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "        MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "    ]\n",
    ").partial(options=str(agent_options), members=\", \".join(agent_tools))\n",
    "\n",
    "# Choose the LLM that will drive the agent\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo-1106\", streaming=True)\n",
    "\n",
    "# Construct the OpenAI Functions agent\n",
    "agent_runnable = create_openai_functions_agent(llm, [router], prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up the Agent State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, Annotated, Sequence, Union\n",
    "import operator\n",
    "from langchain_core.messages import BaseMessage\n",
    "from langchain_core.agents import AgentAction, AgentFinish\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    # The list of previous messages in the conversation\n",
    "    messages: Annotated[Sequence[BaseMessage], operator.add]\n",
    "    # The user's original request\n",
    "    original_request: str\n",
    "    # The input string\n",
    "    # input: str\n",
    "    # The outcome of a given call to the agent\n",
    "    # Needs `None` as a valid type, since this is what this will start as\n",
    "    agent_outcome: Union[AgentAction, AgentFinish, None]\n",
    "    # List of actions and corresponding observations\n",
    "    # Here we annotate this with `operator.add` to indicate that operations to\n",
    "    # this state should be ADDED to the existing values (not overwrite it)\n",
    "    intermediate_steps: Annotated[list[tuple[AgentAction, str]], operator.add]\n",
    "    # The context\n",
    "    context: str\n",
    "    # The code\n",
    "    code: str\n",
    "    # The code quality\n",
    "    code_approved: bool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up the node actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'intermediate_steps': [], 'messages': [], 'agent_outcome': None, 'original_request': 'hello', 'context': '', 'code_approved': False, 'code': ''}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AgentActionMessageLog(tool='route', tool_input={'next': 'Retrieve Context'}, log=\"\\nInvoking: `route` with `{'next': 'Retrieve Context'}`\\n\\n\\n\", message_log=[AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"next\":\"Retrieve Context\"}', 'name': 'route'}})])"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = AgentState(intermediate_steps=[], messages=[], agent_outcome = None, original_request=\"hello\", context=\"\", code_approved=False, code=\"\")\n",
    "print(test)\n",
    "agent_runnable.invoke(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import ToolInvocation\n",
    "import json\n",
    "from langchain_core.messages import FunctionMessage, AIMessage\n",
    "\n",
    "\n",
    "# Define the function that determines whether to continue or not\n",
    "def should_continue(state):\n",
    "    # If the agent outcome is an AgentFinish, then we return `exit` string\n",
    "    # This will be used when setting up the graph to define the flow\n",
    "    if isinstance(state[\"agent_outcome\"], AgentFinish):\n",
    "        return \"end\"\n",
    "    # Otherwise, an AgentAction is returned\n",
    "    # Here we return `continue` string\n",
    "    # This will be used when setting up the graph to define the flow\n",
    "    else:\n",
    "        return \"continue\"\n",
    "\n",
    "\n",
    "# Define the function that calls the model\n",
    "def call_model(state):\n",
    "    # messages = state['messages']\n",
    "    agent_outcome = agent_runnable.invoke(state)\n",
    "    return {\"agent_outcome\": agent_outcome}\n",
    "\n",
    "\n",
    "def call_set_initial_state(state):\n",
    "    messages = state[\"messages\"]\n",
    "    last_message = messages[-1]\n",
    "    return {\"original_request\": last_message.content}\n",
    "\n",
    "\n",
    "# Define the function to execute tools\n",
    "def call_tool(state):\n",
    "    # We construct an ToolInvocation from the function_call\n",
    "    tool = state['agent_outcome'].tool_input['next']\n",
    "    print(\"Running Tool: \", tool)\n",
    "\n",
    "    if tool == \"Retrieve Context\":\n",
    "        print(\"Retreive Context\")\n",
    "        new_message = AIMessage(content=\"You have context now\")\n",
    "        return {\"context\": \"You have context now\", \"messages\": [new_message]}\n",
    "    elif tool == \"Write Code\":\n",
    "        print(\"successfully writing code now\")\n",
    "        code_writing_runnable.invoke({\"context\": \"Some Context\", \"request\": \"My Request\"})\n",
    "        new_message = AIMessage(content=\"You have code now\")\n",
    "        return {\"code\": \"You have context now\", \"messages\": [new_message]}\n",
    "        print(\"Write Code\")\n",
    "    elif tool == \"Review Code\":\n",
    "        print(\"successfully reviewing code now\")\n",
    "        code_writing_runnable.invoke({\"context\": \"Some Context\", \"request\": \"My Request\"})\n",
    "        new_message = AIMessage(content=\"Code is approved\")\n",
    "        return {\"code_approved\": True, \"messages\": [new_message]}\n",
    "        print(\"Write Code\")\n",
    "    elif tool == \"Save Code\":\n",
    "        print(\"Save Code\")\n",
    "\n",
    "    print(\"Slipped through the loop\")\n",
    "    return {\"messages\": [last_message]}\n",
    "\n",
    "    action = ToolInvocation(\n",
    "        tool=last_message.additional_kwargs[\"function_call\"][\"name\"],\n",
    "        tool_input=json.loads(\n",
    "            last_message.additional_kwargs[\"function_call\"][\"arguments\"]\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    # response = input(prompt=f\"[y/n] continue with: {action}?\")\n",
    "    # if response == \"n\":\n",
    "    #     raise ValueError(\"User cancelled\")\n",
    "    # We call the tool_executor and get back a response\n",
    "    response = tool_executor.invoke(action)\n",
    "    # We use the response to create a FunctionMessage\n",
    "    function_message = FunctionMessage(content=str(response), name=action.tool)\n",
    "    # We return a list, because this will get added to the existing list\n",
    "    return {\"messages\": [function_message]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "# Define a new graph\n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "# Define the two nodes we will cycle between\n",
    "workflow.add_node(\"agent\", call_model)\n",
    "workflow.add_node(\"action\", call_tool)\n",
    "workflow.add_node(\"initial_state\", call_set_initial_state)\n",
    "\n",
    "# Set the entrypoint as `agent`\n",
    "# This means that this node is the first one called\n",
    "workflow.set_entry_point(\"initial_state\")\n",
    "\n",
    "# We now add a conditional edge\n",
    "workflow.add_conditional_edges(\n",
    "    # First, we define the start node. We use `agent`.\n",
    "    # This means these are the edges taken after the `agent` node is called.\n",
    "    \"agent\",\n",
    "    # Next, we pass in the function that will determine which node is called next.\n",
    "    should_continue,\n",
    "    # Finally we pass in a mapping.\n",
    "    # The keys are strings, and the values are other nodes.\n",
    "    # END is a special node marking that the graph should finish.\n",
    "    # What will happen is we will call `should_continue`, and then the output of that\n",
    "    # will be matched against the keys in this mapping.\n",
    "    # Based on which one it matches, that node will then be called.\n",
    "    {\n",
    "        # If `tools`, then we call the tool node.\n",
    "        \"continue\": \"action\",\n",
    "        # Otherwise we finish.\n",
    "        \"end\": END,\n",
    "    },\n",
    ")\n",
    "\n",
    "# We now add a normal edge from `tools` to `agent`.\n",
    "# This means that after `tools` is called, `agent` node is called next.\n",
    "workflow.add_edge(\"action\", \"agent\")\n",
    "workflow.add_edge(\"initial_state\", \"agent\")\n",
    "\n",
    "# Finally, we compile it!\n",
    "# This compiles it into a LangChain Runnable,\n",
    "# meaning you can use it as you would any other runnable\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run our agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output from node 'initial_state':\n",
      "---\n",
      "{'original_request': '\\nCreate a chain that does the following:\\n- Accept a string named answer as input\\n- Format a System and Human message using templates. The System message has output instructions via Pydantic. The Human message uses answer as context. Output instructions should require format to a Pydantic schema for hmw_question with a question (up to 10 words) and a role (either CMO, CTO, or CEO) \\n- Pass the messages to OpenAI\\n- Parse the response using Pydantic\\n'}\n",
      "\n",
      "---\n",
      "\n",
      "Output from node 'agent':\n",
      "---\n",
      "{'agent_outcome': AgentActionMessageLog(tool='route', tool_input={'next': 'Retrieve Context'}, log=\"\\nInvoking: `route` with `{'next': 'Retrieve Context'}`\\n\\n\\n\", message_log=[AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"next\":\"Retrieve Context\"}', 'name': 'route'}})])}\n",
      "\n",
      "---\n",
      "\n",
      "Running Tool:  Retrieve Context\n",
      "Retreive Context\n",
      "Output from node 'action':\n",
      "---\n",
      "{'context': 'You have context now', 'messages': [AIMessage(content='You have context now')]}\n",
      "\n",
      "---\n",
      "\n",
      "Output from node 'agent':\n",
      "---\n",
      "{'agent_outcome': AgentActionMessageLog(tool='route', tool_input={'next': 'Write Code'}, log=\"\\nInvoking: `route` with `{'next': 'Write Code'}`\\n\\n\\n\", message_log=[AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"next\":\"Write Code\"}', 'name': 'route'}})])}\n",
      "\n",
      "---\n",
      "\n",
      "Running Tool:  Write Code\n",
      "successfully writing code now\n",
      "Output from node 'action':\n",
      "---\n",
      "{'code': 'You have context now', 'messages': [AIMessage(content='You have code now')]}\n",
      "\n",
      "---\n",
      "\n",
      "Output from node 'agent':\n",
      "---\n",
      "{'agent_outcome': AgentActionMessageLog(tool='route', tool_input={'next': 'Review Code'}, log=\"\\nInvoking: `route` with `{'next': 'Review Code'}`\\n\\n\\n\", message_log=[AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"next\":\"Review Code\"}', 'name': 'route'}})])}\n",
      "\n",
      "---\n",
      "\n",
      "Running Tool:  Review Code\n",
      "successfully reviewing code now\n",
      "Output from node 'action':\n",
      "---\n",
      "{'code_approved': True, 'messages': [AIMessage(content='Code is approved')]}\n",
      "\n",
      "---\n",
      "\n",
      "Output from node 'agent':\n",
      "---\n",
      "{'agent_outcome': AgentFinish(return_values={'output': 'FINISH'}, log='FINISH')}\n",
      "\n",
      "---\n",
      "\n",
      "Output from node '__end__':\n",
      "---\n",
      "{'messages': [HumanMessage(content='\\nCreate a chain that does the following:\\n- Accept a string named answer as input\\n- Format a System and Human message using templates. The System message has output instructions via Pydantic. The Human message uses answer as context. Output instructions should require format to a Pydantic schema for hmw_question with a question (up to 10 words) and a role (either CMO, CTO, or CEO) \\n- Pass the messages to OpenAI\\n- Parse the response using Pydantic\\n'), AIMessage(content='You have context now'), AIMessage(content='You have code now'), AIMessage(content='Code is approved')], 'original_request': '\\nCreate a chain that does the following:\\n- Accept a string named answer as input\\n- Format a System and Human message using templates. The System message has output instructions via Pydantic. The Human message uses answer as context. Output instructions should require format to a Pydantic schema for hmw_question with a question (up to 10 words) and a role (either CMO, CTO, or CEO) \\n- Pass the messages to OpenAI\\n- Parse the response using Pydantic\\n', 'agent_outcome': AgentFinish(return_values={'output': 'FINISH'}, log='FINISH'), 'intermediate_steps': [], 'context': 'You have context now', 'code': 'You have context now', 'code_approved': True}\n",
      "\n",
      "---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "feature_request = \"\"\"\n",
    "Create a chain that does the following:\n",
    "- Accept a string named answer as input\n",
    "- Format a System and Human message using templates. The System message has output instructions via Pydantic. The Human message uses answer as context. Output instructions should require format to a Pydantic schema for hmw_question with a question (up to 10 words) and a role (either CMO, CTO, or CEO) \n",
    "- Pass the messages to OpenAI\n",
    "- Parse the response using Pydantic\n",
    "\"\"\"\n",
    "\n",
    "inputs = {\"messages\": [HumanMessage(content=feature_request)]}\n",
    "for output in app.stream(inputs):\n",
    "    # stream() yields dictionaries with output keyed by node name\n",
    "    for key, value in output.items():\n",
    "        print(f\"Output from node '{key}':\")\n",
    "        print(\"---\")\n",
    "        print(value)\n",
    "    print(\"\\n---\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='\\nCreate a chain that does the following:\\n- Accept a string named answer as input\\n- Format a System and Human message using templates. The System message has output instructions via Pydantic. The Human message uses answer as context. Output instructions should require format to a Pydantic schema for hmw_question with a question (up to 10 words) and a role (either CMO, CTO, or CEO) \\n- Pass the messages to OpenAI\\n- Parse the response using Pydantic\\n'\n",
      "content='You have context now'\n",
      "content='You have code now'\n",
      "content='Code is approved'\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "message_output = output['__end__']['messages']\n",
    "\n",
    "for message in message_output:\n",
    "    print(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HumanMessage(content='\\nCreate a chain that does the following:\\n- Accept a string named answer as input\\n- Format a System and Human message using templates. The System message has output instructions via Pydantic. The Human message uses answer as context. Output instructions should require format to a Pydantic schema for hmw_question with a question (up to 10 words) and a role (either CMO, CTO, or CEO) \\n- Pass the messages to OpenAI\\n- Parse the response using Pydantic\\n'), AIMessage(content='You have context now'), AIMessage(content='You have code now'), AIMessage(content='Code is approved')]\n"
     ]
    }
   ],
   "source": [
    "print(output['__end__']['messages'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<langgraph.graph.state.StateGraph object at 0x15ac42390>\n"
     ]
    }
   ],
   "source": [
    "print(workflow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
